{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Una guía para entender y hacer modelos de Regresión Lineal\n",
    "\n",
    "> *\"I know I'm stereotypical barbie and therefore don't form conjectures concerning causality of adjacent unfolding events. But some things have been happening that might be related\"* — Barbie (2023)\n",
    "\n",
    "La **regresión lineal** es la base de los modelos de inferencia causal.\n",
    "\n",
    "Hay una razón por la que todos los libros de econometría y de ciencia de datos lo cubren. Se trata del modelo por el que debes comenzar **antes de explorar** modelos más complejos.\n",
    "\n",
    "No hay nada de malo en usar redes neuronales o modelos de random forest en tu proyecto (actualmente está de moda hacer transición de economista a Data Scientist, y alguien que estudia econometría ya lleva un buen avance en los modelos *supervisados*), pero si usas **regresión lineal**, tus modelos tendrán los siguientes beneficios:\n",
    "\n",
    "- Mayor parsimonia. Entre más simple es el modelo, menos problemas te va a causar.\n",
    "- Serán más fáciles de interpretar. Si necesitas comunicar tus resultados a un jefe o un cliente, necesitas poder decir claramente lo que tus datos significan y las limitaciones.\n",
    "- Pruebas de robustez. Cuando un modelo pasa pruebas y demuestra que es robusto, podrás tener más confianza de usarlo en tus predicciones.\n",
    "\n",
    "No es magia. Hay teoremas muy sólidos que ayudan a que entendamos lo que funciona y cuándo funciona.\n",
    "\n",
    "Este capítulo se trata de sentar esas bases sólidas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## El modelo de mínimos cuadrados ordinarios con dos variables\n",
    "\n",
    "Comencemos con el modelo básico. Tienes una variable $X$ y deseas conocer el efecto que tiene sobre $Y$. La variable $X$ podría ser el gasto en una campaña publicitaria por Televisión, mientras que $Y$ son las ventas de nuestro producto.\n",
    "\n",
    "Si tienes suficientes combinaciones de las dos variables, puedes plantear un modelo sobre su comportamiento. Usaremos la base de datos de publicidad, disponible libremente en [kaggle.com](http://kaggle.com/). El siguiente código carga la base de datos directamente del repositorio y muestra un diagrama de dispersión entre los gastos en publicidad por TV y las ventas en millones de unidades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import pandas as pd\nimport matplotlib.pyplot as plt\n\n# Cargar los datos\ndata = pd.read_csv('../../data/advertising.csv')\n\n# Crear un diagrama de dispersión\nplt.figure(figsize=(10, 6))\nplt.scatter(data['TV'], data['Sales'], alpha=0.5)\nplt.title('Diagrama de Dispersión de Gastos en TV vs Ventas')\nplt.xlabel('Gastos en TV ($)')\nplt.ylabel('Ventas (Miles de unidades)')\nplt.grid(True)\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Diagrama de dispersión generado a partir del bloque de código de Python.](../../figures/scatter1.png)\n",
    "\n",
    "Este es un ejemplo muy claro donde la regresión lineal es el modelo ideal para nosotros: los puntos siguen un patrón muy claro visualmente.\n",
    "\n",
    "Lo que nos dice la regresión lineal es que existe una línea que se ajusta a los datos. No necesitamos que el ajuste sea perfecto (si tuviéramos un ajuste perfecto no necesitaríamos de modelos estadísticos). Es normal pensar que hay muchos factores que afectan las ventas además del gasto publicitario, desde el clima hasta el día del mes pueden generar variaciones.\n",
    "\n",
    "Así se ve nuestra línea de regresión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.regplot(x='TV', y='Sales', data=data, scatter_kws={'alpha':0.5})\n",
    "plt.title('Diagrama de Dispersión de Gastos en TV vs Ventas con Línea de Regresión')\n",
    "plt.xlabel('Gastos en TV ($)')\n",
    "plt.ylabel('Ventas (Miles de unidades)')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Diagrama de dispersión con línea de regresión.](../../figures/scatter2.png)\n",
    "\n",
    "Este tipo de línea se genera con un modelo lineal, donde cada punto es producto de una función de tipo\n",
    "\n",
    "$$Y_{i}=\\beta_{0}+\\beta_{1}X_{i}+\\varepsilon_{i}$$\n",
    "\n",
    "El punto $i$ se ubica en la coordenada $(X_{i}, Y_{i})$. El término $\\varepsilon_{i}$ es el **error**, la diferencia entre el punto y la línea. Los términos $\\beta_{0}$ y $\\beta_{1}$ (*se lee beta-cero y beta-uno*) son los parámetros de una función lineal.\n",
    "\n",
    "Nota que en algunos puntos, la línea de regresión \"se equivoca\" hacia arriba y en otros puntos hacia abajo. Cada punto que compone la línea de regresión es una predicción del valor de $Y_{i}$ dado $X_{i}$, donde $\\varepsilon_{i}$ es la diferencia, a la que llamamos el **residual**.\n",
    "\n",
    "![Le llamamos \"error\" a la diferencia entre una observación y la línea de regresión que \"predice\" dónde debería estar $Y_i$ dado $X_i$.](../../figures/error.png)\n",
    "\n",
    "El modelo lineal tiene la ventaja de que sólo con dos parámetros podemos definir toda la línea.\n",
    "\n",
    "Si $\\beta_{0}=6.97$ y $\\beta_{1}=0.0554$, entonces un valor de $X_{i}=\\$150$ en gasto de publicidad por TV implica ventas por $15.29$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sales(tv):\n",
    "    b0 = 6.97\n",
    "    b1 = 0.0555\n",
    "    return b0 + b1 * tv\n",
    "\n",
    "sales(150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## El método de Mínimos cuadrados ordinarios\n",
    "\n",
    "El método de **Mínimos Cuadrados Ordinarios** (OLS, por sus siglas en inglés) es el método más popular para resolver el modelo de regresión lineal. Se prefiere porque es simple y muy eficiente.\n",
    "\n",
    "Bajo ciertas condiciones, OLS se considera el mejor estimador lineal insesgado. El acrónimo en inglés es BLUE (Best Linear Unbiased Estimator):\n",
    "\n",
    "- **Best** (Mejor): Significa que tiene la menor varianza de las estimaciones.\n",
    "- **Linear** (Lineal): El estimador es una función lineal de los valores observados.\n",
    "- **Unbiased** (Insesgados): El estimador le *atina* al verdadero valor del parámetro **en promedio**.\n",
    "- **Estimator** (Estimador): Es la regla o fórmula que indica cómo estimar los parámetros del modelo.\n",
    "\n",
    "OLS tiene el objetivo de encontrar los valores de $\\beta_{0}$ y $\\beta_{1}$ que minimizan la suma de los errores al cuadrado.\n",
    "\n",
    "![El objetivo del método de mínimos cuadrados es encontrar la línea que minimice la suma de los errores al cuadrado.](../../figures/errores2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obteniendo los estimadores de OLS\n",
    "\n",
    "Pasemos la ecuación a notación vectorial. Sea $\\mathbf{Y}$ el vector de observaciones de tamaño $n\\times1$, $\\mathbf{X}$ una matriz de tamaño $n\\times k$, $\\boldsymbol{\\beta}$ un vector de tamaño $k+1\\times1$, y $\\boldsymbol{\\varepsilon}$ un vector de errores de tamaño $n\\times1$.\n",
    "\n",
    "Nuestro modelo se puede representar de forma compacta como $\\mathbf{Y} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\varepsilon}$.\n",
    "\n",
    "La suma de los residuales al cuadrado (RSS) la expresamos como $\\mathbf{e}'\\mathbf{e}$:\n",
    "\n",
    "$$\\mathbf{e}'\\mathbf{e} = \\mathbf{y}'\\mathbf{y} - 2\\hat{\\boldsymbol\\beta}'\\mathbf{X}'\\mathbf{y} + \\hat{\\boldsymbol\\beta}'\\mathbf{X}'\\mathbf{X} \\hat{\\boldsymbol\\beta}$$\n",
    "\n",
    "Las condiciones de primer orden:\n",
    "\n",
    "$$\\frac{\\partial \\mathbf{e'e}}{\\partial \\hat{\\boldsymbol\\beta}}=-2\\mathbf{X}'\\mathbf{y}+2\\mathbf{X}'\\mathbf{X}\\hat{\\boldsymbol\\beta}=0$$\n",
    "\n",
    "De donde obtenemos las ecuaciones normales:\n",
    "\n",
    "$$(\\mathbf{X}'\\mathbf{X})\\hat{\\boldsymbol\\beta}=\\mathbf{X}'\\mathbf{y}$$\n",
    "\n",
    "Y por lo tanto:\n",
    "\n",
    "$$\\hat{\\boldsymbol\\beta}=(\\mathbf{X}'\\mathbf{X})^{-1}\\mathbf{X}'\\mathbf{y}$$\n",
    "\n",
    "Esto es lo que tu computadora calcula cuando le pides que haga una regresión lineal con tus datos.\n",
    "\n",
    "Hagamos un ejercicio en Python con los datos de publicidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import numpy as np\nimport pandas as pd\n\nruta_archivo = '../../data/advertising.csv'\ndatos = pd.read_csv(ruta_archivo)\n\ntv = datos['TV'].values\nventas = datos['Sales'].values\n\nX = np.column_stack((np.ones(tv.shape[0]), tv))\n\nXX_inv = np.linalg.inv(X.T @ X)\nbeta_hat = XX_inv @ X.T @ ventas\n\nintercepto, pendiente = beta_hat\n\nprint(\"Intercepto:\", intercepto)\nprint(\"Pendiente para TV:\", pendiente)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Propiedades de los estimadores de Mínimos Cuadrados\n",
    "\n",
    "Podemos deducir varias propiedades de los estimadores. Verifiquemos cada una con Python.\n",
    "\n",
    "### Los valores observados de $\\mathbf{X}$ no están correlacionados con los residuales\n",
    "\n",
    "Que $\\mathbf{X}'\\mathbf{e}=0$ implica que cada columna de la matriz $\\mathbf{X}$ tiene correlación muestral de cero con los residuales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicciones = X @ beta_hat\n",
    "residuales = ventas - predicciones\n",
    "\n",
    "correlacion = np.corrcoef(tv, residuales)[0, 1]\n",
    "print(\"Correlación entre los valores observados de TV y los residuales:\", correlacion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El coeficiente de correlación es prácticamente cero. Esto comprueba la propiedad.\n",
    "\n",
    "### La suma de los residuales es igual a cero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suma_residuales = np.sum(residuales)\n",
    "print(\"Suma de los residuales:\", suma_residuales)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### La media muestral de los residuales es cero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "media_residuales = np.mean(residuales)\n",
    "print(\"Media de los residuales:\", media_residuales)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### El hiperplano de la regresión pasa a través de las medias de los valores observados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "promedio_tv = np.mean(tv)\n",
    "promedio_ventas = np.mean(ventas)\n",
    "ventas_predichas_en_promedio_tv = beta_hat[0] + beta_hat[1] * promedio_tv\n",
    "\n",
    "print(\"Promedio de TV:\", promedio_tv)\n",
    "print(\"Promedio de Ventas:\", promedio_ventas)\n",
    "print(\"Ventas predichas cuando TV es igual a su promedio:\", ventas_predichas_en_promedio_tv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Los valores de predicción de $\\mathbf{Y}$ no están correlacionados con los residuales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlacion_predichos_residuales = np.corrcoef(predicciones, residuales)[0, 1]\n",
    "print(\"Correlación entre los valores predichos de Ventas y los residuales:\", correlacion_predichos_residuales)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### La media de las predicciones de $\\mathbf{Y}$ será igual que la media de los $\\mathbf{Y}$ observados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "media_predicciones = np.mean(predicciones)\n",
    "print(\"Media de los valores predichos:\", media_predicciones)\n",
    "print(\"Media de los valores observados (Ventas):\", promedio_ventas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## El teorema de Gauss-Márkov y sus supuestos\n",
    "\n",
    "> *\"I'm BLUE, da-ba-dee-da-ba-day\"* — Eiffel 65 feat. Gabry Ponte\n",
    "\n",
    "El teorema de Gauss-Márkov establece que si tu modelo de regresión lineal satisface cinco supuestos básicos, entonces la regresión por mínimos cuadrados producirá **estimaciones insesgadas** con la varianza mas pequeña de **todos** los estimadores lineales posibles: **BLUE**.\n",
    "\n",
    "![Andrei Márkov (izquierda) y Carl Friedrich Gauss (derecha) jugando ajedrez.](../../figures/gauss-markov.png)\n",
    "\n",
    "## Estos son los supuestos del Teorema de Gauss-Márkov\n",
    "\n",
    "### Supuesto #1: Los parámetros deben ser lineales\n",
    "\n",
    "Si hiciéramos un diagrama de dispersión, deberíamos ver algo parecido a lo que mostró el diagrama de dispersión del gasto en TV contra las ventas.\n",
    "\n",
    "![Un diagrama de dispersión nos muestra que X y Y son variables que no parecen tener ninguna relación entre sí.](../../figures/linear-reg-2dim1.png)\n",
    "\n",
    "Sin embargo, no debemos dejarnos engañar. La regresión lineal la podemos hacer con múltiples dimensiones. En ocasiones, las variables adicionales hacen que la linealidad tenga sentido.\n",
    "\n",
    "![No es sino hasta que agregamos una tercera variable que podemos revelar la verdadera relación.](../../figures/linear-reg-2dim2.png)\n",
    "\n",
    "### Supuesto #2: Los datos deben ser tomados de un muestreo aleatorio de la población\n",
    "\n",
    "Este es un supuesto básico: nuestra muestra debe ser aleatoria. Si no lo hacemos de esta manera, nos arriesgamos a encontrar sesgos en nuestras bases de datos.\n",
    "\n",
    "### Supuesto #3: No hay colinealidad\n",
    "\n",
    "Los regresores no están correlacionados perfectamente entre sí. En nuestro modelo de álgebra lineal, esto se determina cuando $\\mathbf{X}$ es una matriz de rango completo (si $\\mathbf{X}$ no tiene rango completo, no se puede calcular la matriz $(\\mathbf{X}^\\top \\mathbf{X})^{-1}$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import numpy as np\nimport pandas as pd\n\nruta_archivo = '../../data/advertising.csv'\ndatos = pd.read_csv(ruta_archivo)\n\ntv = datos['TV'].values\nradio = datos['Radio'].values\nnewspaper = datos['Newspaper'].values\nventas = datos['Sales'].values\n\nX = np.column_stack((np.ones(tv.shape[0]), tv, radio, newspaper))\n\nrango_X = np.linalg.matrix_rank(X)\nprint(\"Rango de la matriz X:\", rango_X)\n\nnum_columnas = X.shape[1]\nes_rango_completo = rango_X == num_columnas\nprint(\"¿Es la matriz X de rango completo (sin multicolinealidad)?\", es_rango_completo)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La forma tradicional de verificar este supuesto es revisar las correlaciones entre las variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matriz_correlacion = datos[['TV', 'Radio', 'Newspaper']].corr()\n",
    "print(\"Matriz de correlación:\\n\", matriz_correlacion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La correlación más alta es entre el gasto en periódico y el de radio, con un 35%. Calculemos también el **factor de inflación de la varianza** (VIF):\n",
    "\n",
    "$$\\text{VIF}_j = \\frac{1}{1 - R^2_j}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "def calcular_vif(X):\n",
    "    vif = pd.DataFrame()\n",
    "    vif[\"variables\"] = X.columns\n",
    "    vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "    return vif\n",
    "\n",
    "vif_df = calcular_vif(datos[['TV', 'Radio', 'Newspaper']])\n",
    "print(\"VIF para cada variable:\\n\", vif_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todos los factores están por debajo de 5, por lo que **no hay problemas de multicolinealidad** en nuestros datos.\n",
    "\n",
    "### Supuesto #4: Exogeneidad\n",
    "\n",
    "También se le conoce como el supuesto de media condicional cero, y es probablemente el supuesto más crítico para la inferencia causal:\n",
    "\n",
    "$$E(\\epsilon|\\mathbf{X})=0$$\n",
    "\n",
    "La manera más práctica de comprobarlo es con un gráfico de las predicciones con los residuales.\n",
    "\n",
    "![Los residuales y los valores de predicción no muestran estar correlacionados.](../../figures/Residuals vs. Predicted Sales.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import pandas as pd\nimport statsmodels.api as sm\nimport matplotlib.pyplot as plt\n\nfile_path = '../../data/advertising.csv'\ndata = pd.read_csv(file_path)\n\nX = data[['TV', 'Radio', 'Newspaper']]\ny = data['Sales']\nX = sm.add_constant(X)\n\nmodel = sm.OLS(y, X).fit()\npredictions = model.predict(X)\nresiduals = model.resid\n\nplt.figure(figsize=(10, 6))\nplt.scatter(predictions, residuals, color='black')\nplt.axhline(y=0, color='black', linestyle='--')\nplt.xlabel('Predicted Sales')\nplt.ylabel('Residuals')\nplt.title('Residuales vs. Predicción de ventas')\nplt.grid(True, which='both', linestyle='--', linewidth=0.5)\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este gráfico muestra que no hay un patrón definido, lo cual es bueno.\n",
    "\n",
    "### Supuesto #5: Homoscedasticidad\n",
    "\n",
    "La varianza del error es constante para todos los valores de los regresores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import seaborn as sns\n\ndata = pd.read_csv('../../data/advertising.csv')\nX = data[['TV', 'Radio', 'Newspaper']]\ny = data['Sales']\nX = sm.add_constant(X)\nmodel = sm.OLS(y, X).fit()\nresiduals = model.resid\nfitted = model.fittedvalues\n\nplt.figure(figsize=(10, 6))\nsns.residplot(x=fitted, y=residuals, color='black', lowess=True)\nplt.xlabel('Fitted values')\nplt.ylabel('Residuals')\nplt.title('Residuals vs. Fitted Values')\nplt.axhline(y=0, color='black', linestyle='--')\nplt.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "for i, col in enumerate(['TV', 'Radio', 'Newspaper']):\n",
    "    sns.scatterplot(x=data[col], y=residuals, color='black', ax=axes[i])\n",
    "    axes[i].set_title(f'Residuals vs {col}')\n",
    "    axes[i].set_xlabel(col)\n",
    "    axes[i].set_ylabel('Residuals')\n",
    "    axes[i].axhline(y=0, color='black', linestyle='--')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Gráfico que compara residuales vs cada uno de los predictores.](../../figures/Comparativa residuals.png)\n",
    "\n",
    "Usemos la prueba Breusch-Pagan para comprobar formalmente. La hipótesis nula es que los errores del modelo tienen varianza constante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.diagnostic import het_breuschpagan\n",
    "\n",
    "bp_test = het_breuschpagan(residuals, model.model.exog)\n",
    "bp_test_statistic, bp_test_pvalue = bp_test[:2]\n",
    "\n",
    "bp_test_statistic, bp_test_pvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como el p-value es mayor a 0.05, no podemos rechazar la hipótesis nula de homoscedasticidad.\n",
    "\n",
    "## Cómo interpretar el reporte de regresión\n",
    "\n",
    "Hay dos usos para un modelo de regresión: predicción o inferencia.\n",
    "\n",
    "En la **inferencia**, estamos tratando de saber **por qué** una variable se comporta de cierta manera. En predicción, estamos intentando construir un modelo que reconstruya un resultado con información dada.\n",
    "\n",
    "Hagamos la regresión lineal de un modelo por mínimos cuadrados:\n",
    "\n",
    "$$Y=\\beta_{0}+\\beta_{1}X_{1}+\\beta_{2}X_{2}+\\beta_{3}X_{3}+\\varepsilon$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "X = data[['TV', 'Radio', 'Newspaper']]\n",
    "y = data['Sales']\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "model = sm.OLS(y, X).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a interpretar este resultado parte por parte.\n",
    "\n",
    "- **R cuadrada y R cuadrada ajustada**: Una $R^{2}$ de 0.903 significa que un 90.3% de la variación en las ventas se explica por el modelo.\n",
    "- **El estadístico F**: Un estadístico F grande (605.4) indica que la hipótesis nula de que todos los coeficientes son cero es falsa.\n",
    "- **Grados de libertad**: Se refiere al número de observaciones menos el número de parámetros estimados.\n",
    "- **AIC y BIC**: Criterios que se usan para la selección de modelos.\n",
    "\n",
    "**Columna #1: Coeficientes.** Determina el valor de tus betas. `const = 4.6251` significa que si el gasto en publicidad fuera cero, aún tendríamos ventas de cuatro mil seiscientas unidades aproximadamente.\n",
    "\n",
    "**Columna #2: Errores estándar.** Es el ruido de nuestros datos. Entre más grande sea, menos significativo será el modelo.\n",
    "\n",
    "**Columna #3: Estadístico t.** Es una razón entre la *señal* y el *ruido*. Entre más grande sea su valor absoluto, más probable es que los resultados sean significativos.\n",
    "\n",
    "**Columna #4: p-value.** Indica la probabilidad de obtener un resultado al menos tan extremo como el observado, bajo el supuesto de que $\\beta_i = 0$. Un p-value menor a 0.05 implica que los resultados son significativos.\n",
    "\n",
    "![El 5% del p-value es lo mismo que uno en veinte.](../../figures/significant.png)\n",
    "\n",
    "**Columnas #5 y #6: Intervalos de confianza.** Son el rango en el que se encuentra el verdadero valor del parámetro beta. Tenemos un 95% de certidumbre de que el efecto de los anuncios por TV va de 0.052 a 0.057.\n",
    "\n",
    "## ¿Qué pasa si mi regresión no cumple con los supuestos?\n",
    "\n",
    "Algunas acciones que puedes tomar:\n",
    "\n",
    "- Revisa la especificación del modelo.\n",
    "- Transforma los datos.\n",
    "- Usa técnicas robustas.\n",
    "- Incorpora variables adicionales o interacciones.\n",
    "- Considera métodos no paramétricos.\n",
    "\n",
    "La calidad de los datos es mucho más importante que los modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apéndice\n",
    "\n",
    "### ¿Por qué $\\mathbf{e}'\\mathbf{e}$ es la suma de residuos al cuadrado?\n",
    "\n",
    "$$\\begin{bmatrix} e_1 & e_2 & \\cdots & e_n \\end{bmatrix} \\begin{bmatrix} e_1 \\\\ e_2 \\\\ \\vdots \\\\ e_n \\end{bmatrix} = e_1^2 + e_2^2 + \\cdots + e_n^2$$\n",
    "\n",
    "### Guía breve de diferenciación con matrices\n",
    "\n",
    "Sean $a$ y $b$ vectores de tamaño $k \\times 1$:\n",
    "\n",
    "$$\\frac{\\partial a'b}{\\partial b} = \\frac{\\partial b'a}{\\partial b} = a$$\n",
    "\n",
    "Sea $A$ una matriz simétrica:\n",
    "\n",
    "$$\\frac{\\partial b'A b}{\\partial b} = 2Ab = 2b'A$$\n",
    "\n",
    "### ¿Cómo funciona el coeficiente de correlación?\n",
    "\n",
    "El coeficiente de correlación lineal va de -1 a 1:\n",
    "\n",
    "- El signo indica la dirección de la correlación.\n",
    "- El valor absoluto indica la fuerza de la relación.\n",
    "- Una correlación de $0$ indica que no hay relación lineal.\n",
    "- La correlación no implica causalidad.\n",
    "\n",
    "![Hay una correlación entre el número de premios Nobel que gana un país y su consumo de chocolate.](../../figures/nobel.png)\n",
    "\n",
    "### ¿Cómo funciona el VIF?\n",
    "\n",
    "El **VIF** evalúa cuánto se incrementa la varianza de un coeficiente debido a la multicolinealidad:\n",
    "\n",
    "$$VIF = \\frac{1}{1-R^2}$$\n",
    "\n",
    "Interpretación:\n",
    "- VIF de 1: no hay correlación.\n",
    "- VIF entre 1 y 5: correlación moderada.\n",
    "- VIF mayor a 5: correlación problemática.\n",
    "- VIF mayor a 10: multicolinealidad severa.\n",
    "\n",
    "### ¿Por qué es importante identificar la multicolinealidad?\n",
    "\n",
    "1. **Estimaciones inestables de los coeficientes**\n",
    "2. **Confianza reducida en la significancia**\n",
    "3. **Interpretaciones difíciles**\n",
    "4. **Modelos sobreajustados**\n",
    "5. **Dificultad en la selección de modelos**\n",
    "\n",
    "### El supuesto de media condicional cero\n",
    "\n",
    "Es el supuesto más crítico. Establece que los regresores no deben estar correlacionados con el término de error: $E(\\epsilon|\\mathbf{X})=0$.\n",
    "\n",
    "En la práctica, implica que no debe existir ningún patrón en los residuales. Si encontramos endogeneidad, el truco es:\n",
    "\n",
    "1. Regresar a la teoría y encontrar la variable que falta.\n",
    "2. Incluir la variable o una proxy apropiada.\n",
    "3. Volver a hacer las pruebas.\n",
    "\n",
    "### Un poco extra sobre Gauss\n",
    "\n",
    "Gauss es uno de los matemáticos más famosos. La historia más conocida sobre su infancia es la de aquella vez que un maestro les dejó [sumar todos los números del 1 al 100](https://www.americanscientist.org/article/gausss-day-of-reckoning). Gauss llegó casi al instante con la respuesta: $101\\times50 = 5050$.\n",
    "\n",
    "$$\\sum_{i=1}^{n} i = \\frac{n(n+1)}{2}$$\n",
    "\n",
    "### Pruebas de hipótesis\n",
    "\n",
    "Las pruebas de hipótesis son procedimientos estadísticos para determinar si hay suficiente evidencia para inferir que una condición es verdadera para toda la población. Se basan en la hipótesis nula ($H_0$) y la hipótesis alternativa ($H_1$).\n",
    "\n",
    "En un modelo de regresión lineal, se utilizan para probar: linealidad, independencia de los residuos, homocedasticidad, normalidad de los residuos y ausencia de multicolinealidad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumen del capítulo\n",
    "\n",
    "En este capítulo construimos, pieza por pieza, la herramienta más importante de la econometría: la **regresión lineal**.\n",
    "\n",
    "Empezamos con una idea simple: trazar una línea recta que resuma la relación entre dos variables. Después, nos metimos a la sala de máquinas para ver cómo funciona por dentro. Vimos que el método de **OLS** encuentra la mejor línea posible minimizando los errores al cuadrado, y hasta nos atrevimos a deducir la fórmula matemática usando álgebra de matrices. Lo más importante: aprendimos los cinco supuestos del Teorema de Gauss-Márkov, que son las reglas del juego que garantizan que nuestras estimaciones sean las mejores posibles (o sea, **BLUE**). Finalmente, aprendimos a descifrar la tabla de resultados que nos da Python.\n",
    "\n",
    "Ahora tienes un flujo de trabajo completo. Puedes tomar un conjunto de datos, plantear una hipótesis, correr un modelo de regresión, y lo más crucial, diagnosticar si puedes confiar en sus resultados.\n",
    "\n",
    "Ya puedes interpretar un coeficiente y decir con confianza: \"manteniendo todo lo demás constante (*ceteris paribus*), un aumento de X unidades en esta variable se asocia con un cambio de $\\beta$ unidades en el resultado\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Poniendo a prueba la regresión: manos al código y a la mente\n",
    "\n",
    "1. **Interpretando coeficientes:** Viendo la tabla final de resultados de `statsmodels`:\n",
    "    - Explica en una sola frase qué significa el coeficiente de `Radio` (0.1070).\n",
    "    - El coeficiente de `Newspaper` es casi cero y su **p-value** es altísimo (0.954). ¿Qué conclusión práctica sacarías sobre invertir en publicidad en periódicos?\n",
    "    - El intercepto (`const`) es 4.6251. ¿Qué significaría este número en el mundo real?\n",
    "\n",
    "2. **OLS desde las entrañas (Código):** Usando solo `numpy`, construye la matriz $\\mathbf{X}$ (con una columna de unos, 'TV', 'Radio' y 'Newspaper') y el vector $\\mathbf{y}$ ('Sales'). Calcula $\\hat{\\beta}$ usando la fórmula $(\\mathbf{X}'\\mathbf{X})^{-1}\\mathbf{X}'\\mathbf{y}$. Verifica que los coeficientes son idénticos a los de `statsmodels`.\n",
    "\n",
    "3. **Creando multicolinealidad (Conceptual y Código):** Crea una nueva columna `Newspaper_cents` que sea el gasto en periódicos multiplicado por 100. ¿Qué pasaría con el supuesto de \"No multicolinealidad\"?\n",
    "\n",
    "4. **El diagnóstico visual:** ¿Qué dos supuestos de Gauss-Markov puedes evaluar con el gráfico de residuales vs predichos? ¿Cómo se vería un gráfico \"saludable\" vs uno \"enfermo\"?\n",
    "\n",
    "5. **Corriendo un modelo alternativo (Código):** Corre una nueva regresión usando *únicamente* `Radio` y `Newspaper`. Muestra la tabla de resultados.\n",
    "\n",
    "6. **Comparando modelos:** Compara el modelo del ejercicio anterior con el original. ¿Qué pasó con el coeficiente de `Newspaper`?\n",
    "\n",
    "7. **El supuesto más importante (Conceptual):** ¿Qué problema fundamental causa una variable omitida correlacionada tanto con $X$ como con $Y$?\n",
    "\n",
    "8. **Leyendo los intervalos de confianza:** El intervalo para `TV` es [0.052, 0.057]. Explica este rango como si hablaras con tu jefe.\n",
    "\n",
    "9. **Un VIF problemático (Código):** Crea `Radio_y_Diario = Radio + Newspaper`. Calcula el VIF incluyendo esta nueva variable. ¿Qué les pasó a los VIFs?\n",
    "\n",
    "10. **Reto - ¿Relación no lineal?** Crea `TV_cuadrado = data['TV']**2`. Corre una regresión con `TV` y `TV_cuadrado`. ¿Qué te sugiere sobre la relación?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
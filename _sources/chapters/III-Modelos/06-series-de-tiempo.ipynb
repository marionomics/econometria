{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Series de Tiempo\n",
    "\n",
    "> *\"The way I see it, every life is a pile of good things and bad things. The good things don't always soften the bad things, but vice versa, the bad things don't always spoil the good things and make them unimportant.\"* — The Doctor\n",
    "\n",
    "> *\"It's tough to make predictions, especially about the future.\"* — Yogi Berra\n",
    "\n",
    "## Introducción\n",
    "\n",
    "Las series de tiempo son una de las herramientas más poderosas en la econometría aplicada. En esencia, una serie de tiempo combina **modelos estadísticos** con **registros de datos ordenados cronológicamente** para encontrar patrones y hacer pronósticos.\n",
    "\n",
    "¿Para qué sirven las series de tiempo en los negocios y la economía?\n",
    "\n",
    "- **Proyección de ventas**: Estimar cuánto venderá una empresa en los próximos meses o años.\n",
    "- **Predicción de demanda**: Anticipar la demanda de un producto para optimizar inventarios.\n",
    "- **Finanzas**: Modelar el comportamiento de precios de acciones, tipos de cambio y tasas de interés.\n",
    "- **Energía**: Pronosticar el consumo eléctrico o la producción de energía renovable.\n",
    "- **Mercados**: Analizar tendencias en mercados de commodities, bienes raíces y más.\n",
    "- **Inventarios**: Planificar la cadena de suministro con base en patrones históricos.\n",
    "\n",
    "En este capítulo aprenderemos los fundamentos de los modelos de series de tiempo, desde la caminata aleatoria hasta el modelo ARIMA, con ejemplos prácticos en Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Un ejemplo de una Serie de Tiempo\n",
    "\n",
    "Comencemos con el modelo más sencillo de una serie de tiempo: la **caminata aleatoria** (*random walk*).\n",
    "\n",
    "La caminata aleatoria se define como:\n",
    "\n",
    "$$X_t = X_{t-1} + \\varepsilon_t$$\n",
    "\n",
    "donde $\\varepsilon_t \\sim N(0, \\sigma^2)$ es un término de error aleatorio (ruido blanco).\n",
    "\n",
    "En palabras simples: el valor de hoy es igual al valor de ayer más un choque aleatorio. No hay tendencia, no hay patrón predecible. Es como lanzar una moneda en cada paso y decidir si subes o bajas.\n",
    "\n",
    "A pesar de su simplicidad, la caminata aleatoria es un modelo fundamental porque muchas series financieras se comportan de forma similar. Si los precios de una acción siguen una caminata aleatoria, entonces no es posible predecir su dirección futura con base en su historia.\n",
    "\n",
    "Simulemos una caminata aleatoria con Python.\n",
    "\n",
    "![Caminata aleatoria](../../figures/random_walk.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(42)\n",
    "N = 100\n",
    "sigma = 1\n",
    "X_0 = 0\n",
    "\n",
    "X_t = np.zeros(N)\n",
    "X_t[0] = X_0\n",
    "\n",
    "for t in range(1, N):\n",
    "    epsilon = np.random.normal(0, sigma)\n",
    "    X_t[t] = X_t[t-1] + epsilon\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(X_t, label='$X_t$')\n",
    "plt.xlabel('Paso del tiempo')\n",
    "plt.ylabel('Valor')\n",
    "plt.title('Simulación de $X_t = X_{t-1} + \\\\varepsilon$')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observa cómo la serie parece tener tendencias y patrones, pero en realidad es completamente aleatoria. Esto es una propiedad importante de la caminata aleatoria: puede engañar al ojo humano haciéndonos creer que hay un patrón donde no lo hay.\n",
    "\n",
    "### Estacionariedad\n",
    "\n",
    "Una serie de tiempo es **estacionaria** si sus propiedades estadísticas (media, varianza y autocovarianza) no cambian a lo largo del tiempo. La estacionariedad es un supuesto fundamental para la mayoría de los modelos de series de tiempo.\n",
    "\n",
    "Una caminata aleatoria **no es estacionaria** porque su varianza crece con el tiempo: $\\text{Var}(X_t) = t \\cdot \\sigma^2$.\n",
    "\n",
    "¿Cómo sabemos si una serie es estacionaria o no? Podemos usar la **prueba de Dickey-Fuller Aumentada** (ADF, por sus siglas en inglés). Esta prueba tiene las siguientes hipótesis:\n",
    "\n",
    "- $H_0$: La serie tiene una raíz unitaria (no es estacionaria).\n",
    "- $H_1$: La serie es estacionaria.\n",
    "\n",
    "Si el p-valor es menor a 0.05, rechazamos $H_0$ y concluimos que la serie es estacionaria.\n",
    "\n",
    "Cuando una serie no es estacionaria, una técnica común es **diferenciarla**. La primera diferencia de una serie $Y_t$ se define como:\n",
    "\n",
    "$$\\Delta Y_t = Y_t - Y_{t-1}$$\n",
    "\n",
    "Si la serie original no es estacionaria pero su primera diferencia sí lo es, decimos que la serie es **integrada de orden 1**, o $I(1)$.\n",
    "\n",
    "Veamos un ejemplo donde simulamos una serie no estacionaria, la diferenciamos y aplicamos la prueba ADF a ambas.\n",
    "\n",
    "![Diferenciación](../../figures/diff.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "np.random.seed(42)\n",
    "n = 100\n",
    "beta0 = 0.5\n",
    "beta1 = 0.01\n",
    "phi = 0.8\n",
    "epsilon = np.random.normal(0, 1, n)\n",
    "t = np.arange(n)\n",
    "\n",
    "y = np.empty(n)\n",
    "y[0] = beta0 + beta1 + epsilon[0]\n",
    "for i in range(1, n):\n",
    "    y[i] = beta0 + beta1 * t[i] + phi * y[i-1] + epsilon[i]\n",
    "\n",
    "y_diff = np.diff(y)\n",
    "\n",
    "adf_result_original = adfuller(y)\n",
    "adf_result_diff = adfuller(y_diff)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "axs[0].plot(t, y, label='Serie Original')\n",
    "axs[0].set_title('Serie de Tiempo No Estacionaria', fontsize=14)\n",
    "axs[0].set_xlabel('Tiempo', fontsize=12)\n",
    "axs[0].set_ylabel('Valor', fontsize=12)\n",
    "axs[0].legend()\n",
    "\n",
    "axs[1].plot(t[1:], y_diff, label='Serie Diferenciada', color='orange')\n",
    "axs[1].set_title('Serie de Tiempo Diferenciada', fontsize=14)\n",
    "axs[1].set_xlabel('Tiempo', fontsize=12)\n",
    "axs[1].set_ylabel('Valor', fontsize=12)\n",
    "axs[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"--- Prueba ADF: Serie Original ---\")\n",
    "print(f\"Estadístico ADF: {adf_result_original[0]:.4f}\")\n",
    "print(f\"p-valor: {adf_result_original[1]:.4f}\")\n",
    "print()\n",
    "print(\"--- Prueba ADF: Serie Diferenciada ---\")\n",
    "print(f\"Estadístico ADF: {adf_result_diff[0]:.4f}\")\n",
    "print(f\"p-valor: {adf_result_diff[1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como puedes ver, la serie original probablemente no pasa la prueba ADF (p-valor alto), lo que indica que no es estacionaria. Pero al diferenciarla, el p-valor cae drásticamente, confirmando que la serie diferenciada sí es estacionaria.\n",
    "\n",
    "Este concepto de diferenciar para lograr estacionariedad es la base de la **I** en ARIMA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## El modelo ARIMA\n",
    "\n",
    "ARIMA significa **A**uto**R**egressive **I**ntegrated **M**oving **A**verage. Vamos a construir la intuición paso a paso.\n",
    "\n",
    "### La parte Autorregresiva: AR(p)\n",
    "\n",
    "Un modelo autorregresivo de orden 1, o **AR(1)**, dice que el valor actual de la serie depende de su valor anterior más un error:\n",
    "\n",
    "$$Y_t = c + \\phi_1 Y_{t-1} + \\varepsilon_t$$\n",
    "\n",
    "donde $c$ es una constante, $\\phi_1$ es el coeficiente autorregresivo y $\\varepsilon_t$ es ruido blanco.\n",
    "\n",
    "Si $|\\phi_1| < 1$, la serie es estacionaria. Si $\\phi_1 = 1$, tenemos una caminata aleatoria.\n",
    "\n",
    "Podemos generalizar a un modelo **AR(p)** que incluye $p$ rezagos:\n",
    "\n",
    "$$Y_t = c + \\phi_1 Y_{t-1} + \\phi_2 Y_{t-2} + \\cdots + \\phi_p Y_{t-p} + \\varepsilon_t$$\n",
    "\n",
    "Piénsalo así: las ventas de hoy dependen de las ventas de los últimos $p$ días. Un modelo AR(3) usa los tres valores previos para predecir el actual.\n",
    "\n",
    "Simulemos un proceso AR(3) con 1000 observaciones.\n",
    "\n",
    "![AR(3) simulado](../../figures/ar3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(42)\n",
    "n = 1000\n",
    "phi = [0.5, -0.2, 0.1]  # Coeficientes AR(3)\n",
    "p = len(phi)\n",
    "epsilon = np.random.normal(0, 1, n)\n",
    "\n",
    "y = np.zeros(n)\n",
    "for t in range(p, n):\n",
    "    y[t] = phi[0] * y[t-1] + phi[1] * y[t-2] + phi[2] * y[t-3] + epsilon[t]\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(y, linewidth=0.8)\n",
    "plt.title('Simulación de un proceso AR(3)', fontsize=14)\n",
    "plt.xlabel('Tiempo', fontsize=12)\n",
    "plt.ylabel('Valor', fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora verifiquemos que esta serie simulada es estacionaria usando la prueba ADF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "adf_result = adfuller(y)\n",
    "\n",
    "print(\"--- Prueba de Dickey-Fuller Aumentada ---\")\n",
    "print(f\"Estadístico ADF: {adf_result[0]:.4f}\")\n",
    "print(f\"p-valor: {adf_result[1]:.6f}\")\n",
    "print(f\"Número de rezagos usados: {adf_result[2]}\")\n",
    "print(f\"Número de observaciones: {adf_result[3]}\")\n",
    "print(\"Valores críticos:\")\n",
    "for key, value in adf_result[4].items():\n",
    "    print(f\"  {key}: {value:.4f}\")\n",
    "\n",
    "if adf_result[1] < 0.05:\n",
    "    print(\"\\nConclusión: Rechazamos H0. La serie ES estacionaria.\")\n",
    "else:\n",
    "    print(\"\\nConclusión: No rechazamos H0. La serie NO es estacionaria.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datos reales: El IGAE de México\n",
    "\n",
    "Ahora trabajemos con datos reales. El **Indicador Global de la Actividad Económica (IGAE)** es un indicador mensual publicado por el INEGI que mide la evolución de la actividad económica en México. Es como un PIB mensual.\n",
    "\n",
    "Vamos a cargar los datos del IGAE y explorar su comportamiento.\n",
    "\n",
    "![IGAE](../../figures/igae.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Cargar datos del IGAE desde INEGI\n",
    "url = \"https://www.inegi.org.mx/contenidos/programas/igae/2018/tabulados/igae_tabla.xlsx\"\n",
    "\n",
    "try:\n",
    "    igae = pd.read_excel(url)\n",
    "    print(\"Datos cargados exitosamente.\")\n",
    "    print(igae.head())\n",
    "    print(f\"\\nDimensiones: {igae.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"No se pudieron cargar los datos desde INEGI: {e}\")\n",
    "    print(\"Generando datos sintéticos del IGAE para continuar el ejemplo...\")\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    fechas = pd.date_range(start='2010-01-01', periods=168, freq='MS')\n",
    "    tendencia = np.linspace(90, 115, 168)\n",
    "    estacionalidad = 3 * np.sin(2 * np.pi * np.arange(168) / 12)\n",
    "    ruido = np.random.normal(0, 1.5, 168)\n",
    "    valores = tendencia + estacionalidad + ruido\n",
    "    # Simular caída por COVID\n",
    "    valores[122:128] = valores[122:128] - np.array([5, 15, 20, 12, 8, 3])\n",
    "    \n",
    "    igae = pd.DataFrame({'Fecha': fechas, 'IGAE': valores})\n",
    "    igae.set_index('Fecha', inplace=True)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "if 'Fecha' in igae.columns:\n",
    "    plt.plot(igae['Fecha'], igae.iloc[:, 1])\n",
    "else:\n",
    "    plt.plot(igae.index, igae.iloc[:, 0])\n",
    "plt.title('Indicador Global de la Actividad Económica (IGAE)', fontsize=14)\n",
    "plt.xlabel('Fecha', fontsize=12)\n",
    "plt.ylabel('Índice', fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funciones de Autocorrelación (ACF) y Autocorrelación Parcial (PACF)\n",
    "\n",
    "Para decidir qué modelo usar, necesitamos herramientas de diagnóstico. Las dos más importantes son:\n",
    "\n",
    "- **ACF (Función de Autocorrelación)**: Mide la correlación entre $Y_t$ y $Y_{t-k}$ para diferentes rezagos $k$. Incluye efectos directos e indirectos.\n",
    "- **PACF (Función de Autocorrelación Parcial)**: Mide la correlación entre $Y_t$ y $Y_{t-k}$ eliminando el efecto de los rezagos intermedios.\n",
    "\n",
    "**Reglas generales para identificar modelos:**\n",
    "\n",
    "| Modelo | ACF | PACF |\n",
    "|--------|-----|------|\n",
    "| AR(p) | Decae gradualmente | Se corta después del rezago $p$ |\n",
    "| MA(q) | Se corta después del rezago $q$ | Decae gradualmente |\n",
    "| ARMA(p,q) | Decae gradualmente | Decae gradualmente |\n",
    "\n",
    "Veamos las gráficas ACF y PACF de los datos del IGAE, tanto en su forma original como diferenciada.\n",
    "\n",
    "![ACF y PACF originales](../../figures/afc_pafc_original.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "# Usar la serie del IGAE\n",
    "if 'Fecha' in igae.columns:\n",
    "    serie = igae.iloc[:, 1].dropna().values\n",
    "else:\n",
    "    serie = igae.iloc[:, 0].dropna().values\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(14, 5))\n",
    "plot_acf(serie, lags=30, ax=axs[0])\n",
    "axs[0].set_title('ACF - Serie Original', fontsize=14)\n",
    "plot_pacf(serie, lags=30, ax=axs[1])\n",
    "axs[1].set_title('PACF - Serie Original', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora veamos la ACF y PACF de la serie diferenciada.\n",
    "\n",
    "![ACF y PACF diferenciadas](../../figures/afc_pafc_diff.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serie_diff = np.diff(serie)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(14, 5))\n",
    "plot_acf(serie_diff, lags=30, ax=axs[0])\n",
    "axs[0].set_title('ACF - Serie Diferenciada', fontsize=14)\n",
    "plot_pacf(serie_diff, lags=30, ax=axs[1])\n",
    "axs[1].set_title('PACF - Serie Diferenciada', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajustando un modelo AR(3)\n",
    "\n",
    "Supongamos que con base en el análisis de ACF/PACF decidimos ajustar un modelo AR(3). Usaremos la función `AutoReg` de `statsmodels`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.ar_model import AutoReg\n",
    "\n",
    "# Ajustar un modelo AR(3) a la serie diferenciada\n",
    "modelo_ar3 = AutoReg(serie_diff, lags=3).fit()\n",
    "\n",
    "print(modelo_ar3.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selección de modelo con AIC y BIC\n",
    "\n",
    "¿Cómo elegimos entre un AR(2), AR(3) o AR(4)? Usamos criterios de información:\n",
    "\n",
    "- **AIC (Criterio de Información de Akaike)**: Penaliza la complejidad del modelo. Menor es mejor.\n",
    "- **BIC (Criterio de Información Bayesiano)**: Similar al AIC pero con una penalización más fuerte por complejidad. Menor es mejor.\n",
    "\n",
    "$$\\text{AIC} = 2k - 2\\ln(\\hat{L})$$\n",
    "$$\\text{BIC} = k\\ln(n) - 2\\ln(\\hat{L})$$\n",
    "\n",
    "donde $k$ es el número de parámetros, $n$ es el número de observaciones y $\\hat{L}$ es la verosimilitud maximizada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.ar_model import AutoReg\n",
    "\n",
    "resultados = []\n",
    "\n",
    "for p in [2, 3, 4]:\n",
    "    modelo = AutoReg(serie_diff, lags=p).fit()\n",
    "    resultados.append({\n",
    "        'Modelo': f'AR({p})',\n",
    "        'AIC': modelo.aic,\n",
    "        'BIC': modelo.bic\n",
    "    })\n",
    "\n",
    "df_resultados = pd.DataFrame(resultados)\n",
    "print(\"Comparación de modelos AR:\")\n",
    "print(df_resultados.to_string(index=False))\n",
    "print(f\"\\nMejor modelo según AIC: {df_resultados.loc[df_resultados['AIC'].idxmin(), 'Modelo']}\")\n",
    "print(f\"Mejor modelo según BIC: {df_resultados.loc[df_resultados['BIC'].idxmin(), 'Modelo']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pronóstico con el modelo AR\n",
    "\n",
    "Ahora vamos a dividir nuestra serie en un conjunto de **entrenamiento** y uno de **prueba** para evaluar qué tan bien predice nuestro modelo.\n",
    "\n",
    "El **Error Absoluto Medio (MAE)** nos dice, en promedio, cuánto se desvían nuestras predicciones de los valores reales:\n",
    "\n",
    "$$\\text{MAE} = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{y}_i|$$\n",
    "\n",
    "![Pronóstico](../../figures/forecast.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Dividir en entrenamiento (80%) y prueba (20%)\n",
    "n_train = int(len(serie_diff) * 0.8)\n",
    "train = serie_diff[:n_train]\n",
    "test = serie_diff[n_train:]\n",
    "\n",
    "# Ajustar modelo AR(3) en datos de entrenamiento\n",
    "modelo = AutoReg(train, lags=3).fit()\n",
    "\n",
    "# Pronóstico\n",
    "predicciones = modelo.predict(start=n_train, end=len(serie_diff)-1)\n",
    "\n",
    "# Calcular MAE\n",
    "mae = mean_absolute_error(test, predicciones)\n",
    "print(f\"Error Absoluto Medio (MAE): {mae:.4f}\")\n",
    "\n",
    "# Gráfica\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(range(len(train)), train, label='Entrenamiento', color='blue')\n",
    "plt.plot(range(n_train, len(serie_diff)), test, label='Datos reales (prueba)', color='green')\n",
    "plt.plot(range(n_train, len(serie_diff)), predicciones, label='Pronóstico AR(3)', color='red', linestyle='--')\n",
    "plt.axvline(x=n_train, color='black', linestyle=':', label='División train/test')\n",
    "plt.title('Pronóstico AR(3) vs Datos Reales', fontsize=14)\n",
    "plt.xlabel('Tiempo', fontsize=12)\n",
    "plt.ylabel('Valor (diferenciado)', fontsize=12)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Medias Móviles: La MA de ARIMA\n",
    "\n",
    "La parte de **Medias Móviles** (MA) del modelo ARIMA captura la dependencia entre $Y_t$ y los errores pasados. Un modelo MA(q) se define como:\n",
    "\n",
    "$$Y_t = \\mu + \\varepsilon_t + \\theta_1 \\varepsilon_{t-1} + \\theta_2 \\varepsilon_{t-2} + \\cdots + \\theta_q \\varepsilon_{t-q}$$\n",
    "\n",
    "Cuando combinamos la parte AR con la parte MA, obtenemos un modelo **ARMA(p, q)**:\n",
    "\n",
    "$$Y_t = c + \\phi_1 Y_{t-1} + \\cdots + \\phi_p Y_{t-p} + \\varepsilon_t + \\theta_1 \\varepsilon_{t-1} + \\cdots + \\theta_q \\varepsilon_{t-q}$$\n",
    "\n",
    "La intuición es la siguiente:\n",
    "- La parte **AR** captura cómo el pasado de la serie afecta al presente.\n",
    "- La parte **MA** captura cómo los choques (errores) pasados afectan al presente.\n",
    "\n",
    "Simulemos un proceso ARMA(1,3) y ajustemos un modelo.\n",
    "\n",
    "![ARMA](../../figures/arma.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "np.random.seed(42)\n",
    "n = 500\n",
    "\n",
    "# Parámetros ARMA(1,3)\n",
    "phi_1 = 0.6        # Coeficiente AR\n",
    "theta = [0.4, -0.3, 0.2]  # Coeficientes MA\n",
    "epsilon = np.random.normal(0, 1, n + 10)  # extra para inicialización\n",
    "\n",
    "y_arma = np.zeros(n + 10)\n",
    "for t in range(4, n + 10):\n",
    "    y_arma[t] = (phi_1 * y_arma[t-1] + epsilon[t] \n",
    "                 + theta[0] * epsilon[t-1] \n",
    "                 + theta[1] * epsilon[t-2] \n",
    "                 + theta[2] * epsilon[t-3])\n",
    "\n",
    "y_arma = y_arma[10:]  # Descartar observaciones de inicialización\n",
    "\n",
    "# Ajustar modelo ARMA(1,3) usando ARIMA con d=0\n",
    "modelo_arma = ARIMA(y_arma, order=(1, 0, 3)).fit()\n",
    "print(modelo_arma.summary())\n",
    "\n",
    "# Predicciones in-sample\n",
    "pred_arma = modelo_arma.fittedvalues\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(y_arma, label='Serie simulada ARMA(1,3)', alpha=0.7)\n",
    "plt.plot(pred_arma, label='Valores ajustados', color='red', alpha=0.7)\n",
    "plt.title('Modelo ARMA(1,3): Datos vs Valores Ajustados', fontsize=14)\n",
    "plt.xlabel('Tiempo', fontsize=12)\n",
    "plt.ylabel('Valor', fontsize=12)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos la ACF y PACF del proceso ARMA simulado.\n",
    "\n",
    "![ACF y PACF del ARMA](../../figures/arma_afc_pafc.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(14, 5))\n",
    "plot_acf(y_arma, lags=30, ax=axs[0])\n",
    "axs[0].set_title('ACF - Proceso ARMA(1,3)', fontsize=14)\n",
    "plot_pacf(y_arma, lags=30, ax=axs[1])\n",
    "axs[1].set_title('PACF - Proceso ARMA(1,3)', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observa cómo tanto la ACF como la PACF decaen gradualmente, lo cual es consistente con un proceso ARMA. Esto contrasta con un proceso AR puro (donde la PACF se corta abruptamente) o un MA puro (donde la ACF se corta abruptamente)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Y la I del ARIMA?\n",
    "\n",
    "La **I** de ARIMA se refiere a **Integración**. Una serie es integrada de orden $d$ si necesitamos diferenciarla $d$ veces para hacerla estacionaria.\n",
    "\n",
    "Un modelo **ARIMA(p, d, q)** aplica:\n",
    "1. **d** diferenciaciones a la serie para hacerla estacionaria.\n",
    "2. Un modelo **ARMA(p, q)** a la serie diferenciada.\n",
    "\n",
    "Las fórmulas de diferenciación son:\n",
    "\n",
    "**Primera diferencia** ($d = 1$):\n",
    "$$\\Delta Y_t = Y_t - Y_{t-1}$$\n",
    "\n",
    "**Segunda diferencia** ($d = 2$):\n",
    "$$\\Delta^2 Y_t = \\Delta Y_t - \\Delta Y_{t-1} = (Y_t - Y_{t-1}) - (Y_{t-1} - Y_{t-2}) = Y_t - 2Y_{t-1} + Y_{t-2}$$\n",
    "\n",
    "**Tercera diferencia** ($d = 3$):\n",
    "$$\\Delta^3 Y_t = Y_t - 3Y_{t-1} + 3Y_{t-2} - Y_{t-3}$$\n",
    "\n",
    "En la práctica, rara vez necesitamos más de $d = 2$. La mayoría de las series económicas son $I(1)$, es decir, se vuelven estacionarias con una sola diferencia.\n",
    "\n",
    "Por lo tanto, un modelo ARIMA(1, 1, 1) significa:\n",
    "- Diferenciamos la serie una vez ($d = 1$).\n",
    "- Aplicamos un AR(1) y un MA(1) a la serie diferenciada.\n",
    "\n",
    "Esto es exactamente lo que hicimos en secciones anteriores: primero diferenciamos y luego modelamos. ARIMA simplemente lo hace todo en un solo paso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apéndice\n",
    "\n",
    "### Proceso estocástico\n",
    "\n",
    "Un **proceso estocástico** es una colección de variables aleatorias $\\{X_t\\}$ indexadas por el tiempo $t$. Formalmente, es una función $X: T \\times \\Omega \\rightarrow \\mathbb{R}$, donde $T$ es el conjunto de índices temporales y $\\Omega$ es el espacio muestral.\n",
    "\n",
    "Una serie de tiempo es una **realización** de un proceso estocástico: es lo que observamos en la práctica. El proceso estocástico subyacente genera infinitas posibles realizaciones, pero nosotros sólo observamos una.\n",
    "\n",
    "### Ruido blanco\n",
    "\n",
    "Un proceso de **ruido blanco** $\\{\\varepsilon_t\\}$ satisface las siguientes condiciones:\n",
    "\n",
    "1. $E[\\varepsilon_t] = 0$ para todo $t$ (media cero).\n",
    "2. $\\text{Var}(\\varepsilon_t) = \\sigma^2$ para todo $t$ (varianza constante).\n",
    "3. $\\text{Cov}(\\varepsilon_t, \\varepsilon_s) = 0$ para todo $t \\neq s$ (no hay autocorrelación).\n",
    "\n",
    "El ruido blanco es el bloque fundamental de construcción de todos los modelos de series de tiempo. Es la parte que no podemos predecir: el componente puramente aleatorio.\n",
    "\n",
    "### Raíces unitarias\n",
    "\n",
    "Una **raíz unitaria** aparece cuando el polinomio característico del modelo AR tiene una raíz igual a 1. Consideremos un AR(1):\n",
    "\n",
    "$$Y_t = \\phi Y_{t-1} + \\varepsilon_t$$\n",
    "\n",
    "Reescrito como operador de rezago $L$ (donde $LY_t = Y_{t-1}$):\n",
    "\n",
    "$$(1 - \\phi L) Y_t = \\varepsilon_t$$\n",
    "\n",
    "La raíz del polinomio $(1 - \\phi z) = 0$ es $z = 1/\\phi$. Si $\\phi = 1$, la raíz es 1, y tenemos una **raíz unitaria**. Esto significa que la serie es una caminata aleatoria y no es estacionaria.\n",
    "\n",
    "La prueba de Dickey-Fuller que usamos anteriormente es precisamente una prueba para detectar raíces unitarias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumen\n",
    "\n",
    "En este capítulo aprendimos los conceptos fundamentales de las series de tiempo:\n",
    "\n",
    "1. **Caminata aleatoria**: El modelo más simple donde $X_t = X_{t-1} + \\varepsilon_t$.\n",
    "2. **Estacionariedad**: Propiedad fundamental que requiere media y varianza constantes. Se verifica con la prueba ADF.\n",
    "3. **Diferenciación**: Técnica para convertir una serie no estacionaria en estacionaria.\n",
    "4. **Modelos AR(p)**: El valor actual depende de $p$ valores pasados.\n",
    "5. **Modelos MA(q)**: El valor actual depende de $q$ errores pasados.\n",
    "6. **ARIMA(p,d,q)**: Combina AR, diferenciación y MA en un solo modelo.\n",
    "7. **ACF y PACF**: Herramientas de diagnóstico para identificar el tipo de modelo.\n",
    "8. **AIC y BIC**: Criterios para seleccionar el mejor modelo.\n",
    "\n",
    "Las series de tiempo son una herramienta esencial para cualquier economista o científico de datos que necesite hacer pronósticos con datos históricos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicios\n",
    "\n",
    "1. Simula una caminata aleatoria con 500 observaciones y $\\sigma = 2$. Grafica el resultado y aplica la prueba ADF. ¿Es estacionaria?\n",
    "\n",
    "2. Genera un proceso AR(2) con coeficientes $\\phi_1 = 0.7$ y $\\phi_2 = -0.3$ y 1000 observaciones. Grafica la ACF y PACF. ¿La PACF se corta después del rezago 2?\n",
    "\n",
    "3. Toma la serie del IGAE y ajusta un modelo ARIMA(1,1,1). Compara su AIC con un ARIMA(2,1,1) y un ARIMA(1,1,2). ¿Cuál es el mejor modelo?\n",
    "\n",
    "4. Simula un proceso MA(2) con $\\theta_1 = 0.8$ y $\\theta_2 = -0.5$. Grafica la ACF. ¿Se corta después del rezago 2?\n",
    "\n",
    "5. Descarga datos de ventas mensuales de alguna empresa pública (puedes usar Yahoo Finance). Aplica la prueba ADF. Si no es estacionaria, diferencia la serie y vuelve a aplicar la prueba.\n",
    "\n",
    "6. Usando los datos del ejercicio anterior, divide en entrenamiento (80%) y prueba (20%). Ajusta un modelo ARIMA y calcula el MAE del pronóstico.\n",
    "\n",
    "7. Simula una caminata aleatoria con deriva (*drift*): $X_t = \\mu + X_{t-1} + \\varepsilon_t$ con $\\mu = 0.1$. ¿Cómo se ve diferente de una caminata aleatoria sin deriva?\n",
    "\n",
    "8. Genera una serie estacionaria AR(1) con $\\phi = 0.9$ (cerca de una raíz unitaria) y otra con $\\phi = 0.3$. Grafica ambas. ¿Cuál se ve más parecida a una caminata aleatoria?\n",
    "\n",
    "9. Investiga sobre el modelo **SARIMA** (ARIMA estacional). ¿Qué parámetros adicionales necesita? Ajusta un SARIMA a los datos del IGAE.\n",
    "\n",
    "10. Compara las predicciones de un modelo ARIMA con un promedio móvil simple de 12 periodos. ¿Cuál tiene menor MAE en datos de prueba?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
